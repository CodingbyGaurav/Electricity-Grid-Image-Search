{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gaura\\OneDrive\\Documents\\Projects\\Grid Part Identification\\Electricity-Grid-Image-Search\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading model: openai/clip-vit-base-patch32\n",
      "CLIP model and processor loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Load Model and Processor\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "\n",
    "# Define the model ID\n",
    "model_id = \"openai/clip-vit-base-patch32\"\n",
    "\n",
    "# Check for GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the processor and model\n",
    "print(f\"Loading model: {model_id}\")\n",
    "processor = CLIPProcessor.from_pretrained(model_id)\n",
    "model = CLIPModel.from_pretrained(model_id).to(device) # Move model to GPU if available\n",
    "\n",
    "print(\"CLIP model and processor loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded: Dataset({\n",
      "    features: ['image'],\n",
      "    num_rows: 7935\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load and Process Dataset\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Define the path to your training data\n",
    "data_dir = \"InsPLAD-det\"\n",
    "# Load the training dataset using 'imagefolder'\n",
    "# This automatically loads images and assigns labels based on subdirectories (if any)\n",
    "# We might not need the labels directly, but it's good structure.\n",
    "# Set trust_remote_code=True if prompted or if it's needed for imagefolder\n",
    "print(\"Loading dataset...\")\n",
    "train_dataset = load_dataset(\"imagefolder\", data_dir=data_dir + \"/train\", split=\"train\")\n",
    "print(f\"Dataset loaded: {train_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Image Processing Function ---\n",
    "def compute_embeddings(image_batch):\n",
    "    \"\"\"\n",
    "    Preprocesses images using the CLIPProcessor and computes embeddings using the CLIPModel.\n",
    "    Handles potential errors with corrupted images.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    valid_indices = [] # Keep track of which images were successfully processed\n",
    "\n",
    "    # Pre-process images individually to handle potential loading errors\n",
    "    for i, img_data in enumerate(image_batch['image']):\n",
    "        try:\n",
    "            # Ensure image is in RGB format\n",
    "            image = img_data.convert(\"RGB\")\n",
    "            images.append(image)\n",
    "            valid_indices.append(i)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Skipping image at index {i} due to error: {e}\")\n",
    "            # Optionally, you could try loading from bytes if path fails:\n",
    "            # try:\n",
    "            #     image = Image.open(io.BytesIO(img_data['bytes'])).convert(\"RGB\")\n",
    "            #     images.append(image)\n",
    "            #     valid_indices.append(i)\n",
    "            # except Exception as e_inner:\n",
    "            #     print(f\"Warning: Skipping image at index {i} due to error (bytes): {e_inner}\")\n",
    "\n",
    "\n",
    "    if not images: # If no images were valid in the batch\n",
    "        return {\"embeddings\": []}\n",
    "\n",
    "    # Process the valid images in a batch\n",
    "    inputs = processor(text=None, images=images, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    # Move inputs to the correct device (GPU/CPU)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Get image embeddings (disable gradient calculation for inference)\n",
    "    with torch.no_grad():\n",
    "        image_features = model.get_image_features(**inputs)\n",
    "\n",
    "    # Move embeddings back to CPU for storage/further processing if needed\n",
    "    embeddings = image_features.cpu().numpy()\n",
    "\n",
    "    # We need to return embeddings corresponding to the original batch structure,\n",
    "    # inserting None or a placeholder for failed images if necessary, but for simplicity\n",
    "    # in mapping, we'll just return the embeddings for the successfully processed images.\n",
    "    # However, datasets mapping usually expects the output to align with the input batch.\n",
    "    # A more robust way handles this alignment, but let's try a simpler direct map first.\n",
    "    # For now, we assume the map function handles potential discrepancies if lengths differ.\n",
    "    # A safer approach would pad the results to match the original batch size.\n",
    "    return {\"embeddings\": embeddings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings (this may take a while)...\n",
      "Embeddings computed and added to the dataset:\n",
      "Dataset({\n",
      "    features: ['image', 'embeddings'],\n",
      "    num_rows: 7935\n",
      "})\n",
      "Example embedding shape: [0.32368314266204834, -0.0077776312828063965, 0.267245888710022, -0.19161367416381836, 0.053290851414203644, -0.36559200286865234, 0.13718417286872864, 0.6847219467163086, -0.6552464365959167, -0.01993478834629059, 0.20937520265579224, -0.4695011377334595, 0.10200235247612, -0.0548650287091732, 0.03850864991545677, 0.16700479388237, -1.3750569820404053, -0.08511523902416229, -0.02725159376859665, -0.4032372832298279, -0.6758159399032593, -0.1930159330368042, -0.09288192540407181, 0.3543173372745514, 0.686080813407898, 0.39208200573921204, -0.011036578565835953, -0.05986612290143967, -0.2303474396467209, -0.3637860417366028, 0.17015764117240906, 0.0865301787853241, 0.06409253180027008, 0.03617081046104431, -0.20874415338039398, 0.18845264613628387, -0.4128386378288269, 0.44660210609436035, 0.6875894665718079, 1.1724520921707153, -0.018593020737171173, 0.06301946938037872, 0.24696901440620422, 0.12024759501218796, -0.3570813238620758, 0.06043991446495056, 0.6140186786651611, 0.15174147486686707, -0.09880655258893967, 0.06166447699069977, 0.040826160460710526, 0.16017279028892517, -0.03681819885969162, -0.3156448304653168, -0.3994772136211395, 0.24783042073249817, -0.04439377784729004, 0.5423014760017395, -0.3107835650444031, -0.12587463855743408, 0.061405643820762634, 0.1452949047088623, 0.18871745467185974, -0.14015698432922363, -0.5298288464546204, -0.2677522599697113, -0.19761651754379272, -0.20519256591796875, -0.5896915197372437, -0.001052267849445343, 0.0032635480165481567, 0.09842567145824432, -0.25293105840682983, -0.33894461393356323, -0.38015109300613403, -0.21489062905311584, 0.07187383621931076, 0.04394400119781494, -0.16563090682029724, -0.12748204171657562, 0.3433246612548828, -0.10164390504360199, -0.09651003777980804, -0.1858786940574646, -0.1543092131614685, -0.32837215065956116, 0.24863694608211517, -0.04438374564051628, 0.5795191526412964, -0.27430009841918945, 0.17831523716449738, -0.051502227783203125, -6.775228500366211, 0.3329446315765381, 0.44418489933013916, 0.6185945272445679, 0.03143812343478203, -0.08682160824537277, 0.02635733224451542, -0.2838878929615021, 0.4536976218223572, 0.26894640922546387, 0.05400434136390686, 0.13895508646965027, -0.5602370500564575, -0.28486377000808716, -2.2810306549072266, -0.23678956925868988, -0.04013300687074661, 0.14271698892116547, 0.4974026381969452, 0.17931626737117767, -0.007917419075965881, -0.22200681269168854, 0.061511360108852386, -0.2311234325170517, -0.3865489363670349, 0.05972546711564064, -0.26064902544021606, 0.26178932189941406, 0.007455865852534771, 0.1560983806848526, 0.069517120718956, -0.04812081530690193, 0.09527456760406494, 0.1234176978468895, -0.247956782579422, -0.03175777196884155, 0.00022167712450027466, 0.07274645566940308, -0.10917140543460846, -0.1554717868566513, -0.08024774491786957, 0.9606496095657349, -0.11635122448205948, 0.10187317430973053, 0.14942245185375214, -0.46480798721313477, -0.17891573905944824, 0.13374698162078857, -0.11139452457427979, 0.49896949529647827, 0.158063605427742, 0.2202167510986328, -0.4213140606880188, -0.4635975658893585, -0.5646133422851562, 0.11969872564077377, -0.06925352662801743, 0.33338233828544617, -0.4529873728752136, -0.11711887270212173, -0.37466683983802795, 0.03372940421104431, 0.22991029918193817, -0.7343228459358215, -0.38501039147377014, 0.18584558367729187, 0.5644587874412537, 0.22350716590881348, -0.3255733251571655, 0.11366349458694458, 0.2537009119987488, 0.18445324897766113, 0.4313206076622009, 0.23273338377475739, 0.31127452850341797, 0.003870743326842785, -0.20405927300453186, -0.3564799427986145, 0.017408594489097595, -0.25536012649536133, 0.464195191860199, 0.19067324697971344, -0.3823571503162384, 0.1324649155139923, 0.7610570192337036, 0.39746302366256714, -0.16123434901237488, -0.09756959974765778, -0.4584231376647949, -0.1607893854379654, 0.39231687784194946, 0.609991729259491, 0.056481361389160156, -0.02962157502770424, -0.5916069746017456, 0.3010619878768921, 0.3694615960121155, -0.12422307580709457, 0.18352238833904266, 0.157128244638443, -0.01680116355419159, -0.14354845881462097, -0.3220303952693939, -0.20728394389152527, 0.49397051334381104, 0.11728496104478836, -0.7547416687011719, 0.1578977108001709, 0.39308661222457886, -0.01119278371334076, -0.339430034160614, 0.3137660026550293, 0.5066874027252197, -0.4640701413154602, -0.23208975791931152, -0.17028026282787323, -0.5062720775604248, -0.054895877838134766, -0.17942124605178833, 0.3294796347618103, 0.21339571475982666, 0.3477175831794739, 0.3039551377296448, -0.16598330438137054, -0.07974407821893692, 0.44235941767692566, -0.15965037047863007, -0.12792252004146576, 0.14800278842449188, 0.06495148688554764, -0.4822830259799957, -0.28307831287384033, -0.11442957818508148, 0.19898934662342072, -0.15811465680599213, 0.3932209610939026, -0.1419757455587387, 0.09340927749872208, 0.43757885694503784, -0.3824598789215088, 0.31561872363090515, 0.1853369176387787, -0.11136917024850845, -0.08309067785739899, -0.09551394730806351, 0.26142507791519165, 0.28049856424331665, 0.43677228689193726, -0.3158184587955475, -0.05566404014825821, -0.09923627227544785, -0.026743208989501, -0.2638525068759918, -0.1700735092163086, 0.1323622316122055, 0.8783661127090454, -0.422215074300766, -0.02177564799785614, 0.026053359732031822, -0.5390021204948425, -0.002611946314573288, 0.1400126814842224, -0.09166818857192993, -0.020419754087924957, 0.27058014273643494, -0.22937142848968506, 1.1134790182113647, 0.14235806465148926, -0.23257745802402496, -0.20786355435848236, 0.36515742540359497, 0.315049946308136, -0.2997609078884125, 0.03707544505596161, -0.179259791970253, 0.25293755531311035, 0.18943536281585693, -0.11185348033905029, -0.7907484173774719, -0.43414562940597534, 0.1130589097738266, -0.3273024260997772, 0.013866811990737915, -0.34410586953163147, 0.10549764335155487, -0.15805234014987946, 0.08795373886823654, -0.07902077585458755, 0.16890963912010193, 0.16919520497322083, -0.057434819638729095, 0.22005942463874817, -0.22579219937324524, -0.22858518362045288, -0.01230684295296669, -0.30906060338020325, 0.19101569056510925, -0.4153735339641571, 0.020793329924345016, -0.4039265811443329, 0.3736504912376404, -0.30636563897132874, -0.3528556227684021, 0.140954852104187, -0.34472575783729553, 0.5919870138168335, 0.13112173974514008, 0.24621838331222534, 0.2814444601535797, -0.12788905203342438, 0.23103807866573334, 0.12583321332931519, 0.24146927893161774, -0.621396005153656, -0.4561384320259094, 0.05683061480522156, 0.36398571729660034, 0.07697302103042603, -0.4336978793144226, 0.33541399240493774, 0.9603136777877808, -0.4088152050971985, 0.4390433132648468, -0.22687479853630066, 0.017809711396694183, -0.32494139671325684, -0.4092247188091278, -0.3619712293148041, 0.5490106344223022, -1.1882007122039795, 0.08904393017292023, -0.06472812592983246, -0.43779730796813965, -0.19240443408489227, 0.08301223069429398, -0.6107684373855591, 0.12532691657543182, 0.2641572058200836, -0.3553626537322998, -0.3507516086101532, 0.30751803517341614, -0.4870065748691559, -0.6090989708900452, 0.2393181324005127, 0.16696752607822418, -0.25878119468688965, -0.1299724280834198, 0.4710826873779297, 0.09846210479736328, -0.2297966182231903, 0.32066795229911804, -0.3715991973876953, 0.05525730550289154, -0.33491307497024536, 0.17577393352985382, 0.28655630350112915, 0.354963093996048, 0.38358935713768005, 0.13443386554718018, -0.4705613851547241, -0.39198294281959534, -0.1235518679022789, -0.013309329748153687, -0.811621904373169, 0.28361013531684875, 0.10532708466053009, -0.2218615561723709, -0.08219070732593536, -1.0312546491622925, 0.436692476272583, 0.6740620732307434, 0.11039087176322937, -0.44290053844451904, 0.09625647962093353, 0.3230637013912201, -0.762469470500946, -0.07519690692424774, 0.16193971037864685, -0.10360713303089142, -0.07688583433628082, 0.4954788088798523, -0.23159068822860718, 0.46226775646209717, 0.2698574960231781, 0.4112229347229004, 0.16413259506225586, -1.0708637237548828, 0.09853675961494446, -0.031542643904685974, 0.04670249670743942, -0.4436977505683899, -0.623668909072876, -0.0697033703327179, 0.33173125982284546, -0.14810863137245178, 0.08294945955276489, -0.0033083483576774597, -1.4967525005340576, -0.8439145088195801, 0.1014384999871254, 0.08591610193252563, -0.08261485397815704, 0.04902864992618561, 0.08527448773384094, -0.014194309711456299, -0.022064208984375, 0.008251696825027466, 0.5507628917694092, 0.04581519961357117, 0.013831958174705505, -0.011101935058832169, -0.6167188882827759, 0.1694869101047516, 0.3914831280708313, 0.26912879943847656, 0.27225029468536377, 0.42886674404144287, -0.0691051110625267, 0.7165569067001343, 0.2770821452140808, -0.25505930185317993, 0.563875675201416, -0.3264828622341156, 0.0363239049911499, -0.27371639013290405, 0.010977774858474731, 0.08983846008777618, -0.02162175625562668, -0.139963299036026, -0.42279067635536194, 0.33434492349624634, -0.32767605781555176, -0.520395815372467, 0.10511363297700882, 0.3109859228134155, 0.050407350063323975, -0.42781999707221985, 0.11055705696344376, 0.2557794749736786, 0.5447006821632385, -0.9214514493942261, -0.04453360289335251, -0.3298516869544983, -0.6947367191314697, -0.5393738746643066, 0.21290338039398193, -0.04373009502887726, -0.021282479166984558, -0.1464141607284546, 0.2335769683122635, -0.5315607190132141, 0.6704803705215454, 0.2335224747657776, 0.2171708345413208, 0.17044992744922638, 0.2818460166454315, -0.25484776496887207, 0.5288475155830383, 0.01283852756023407, -0.228117436170578, 0.03905108571052551, -0.34427836537361145, -0.12936612963676453, 0.25420498847961426, -0.12152396142482758, 0.37763381004333496, -0.17199461162090302, -0.007082253694534302, -0.009179669432342052, 0.0016343332827091217, -0.20359650254249573, -0.14726606011390686, -0.09788523614406586, -0.29448699951171875, -0.03589354455471039, 0.20943230390548706, -0.2760860323905945, -0.14314991235733032, -0.14278331398963928, 0.22370806336402893, 0.2016836404800415, -0.03527446836233139, 0.2212069183588028, -0.13905222713947296, 0.13981834053993225, 0.4354678988456726, 0.06190036982297897, -0.5119094252586365, 0.1576833575963974, 0.4748838245868683, -0.027838610112667084, -0.3163527548313141, 0.09302422404289246, -0.09117338061332703, -0.21539166569709778, 0.22644804418087006, -0.03738084435462952, -0.04468110203742981, 0.25497570633888245, -0.8440040349960327, 0.353721559047699, -0.43217045068740845, 0.039665959775447845, 0.07354358583688736, -0.030057445168495178, -0.35604971647262573, 0.05344883352518082, 0.04564020410180092, -0.46753057837486267, -0.11513695865869522, -0.06979250907897949, 0.1324499547481537, 0.37979429960250854, 0.35877445340156555, 0.1628965437412262, 0.0727538913488388, 0.16985201835632324, 1.1635445356369019, 0.04351620376110077, -0.27003416419029236]\n"
     ]
    }
   ],
   "source": [
    "# --- Apply the function to the dataset ---\n",
    "# Use batched=True for efficiency\n",
    "# This might take a while depending on dataset size and hardware\n",
    "print(\"Computing embeddings (this may take a while)...\")\n",
    "# Note: If you encounter issues with batching due to image errors,\n",
    "# you might need to set batch_size=1, which will be slower.\n",
    "train_dataset_with_embeddings = train_dataset.map(compute_embeddings, batched=True, batch_size=16) # Adjust batch_size as needed\n",
    "\n",
    "print(\"Embeddings computed and added to the dataset:\")\n",
    "print(train_dataset_with_embeddings)\n",
    "\n",
    "# You can access embeddings like this:\n",
    "example_embedding = train_dataset_with_embeddings[0]['embeddings']\n",
    "print(f\"Example embedding shape: {example_embedding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example embedding shape: [0.32368314266204834, -0.0077776312828063965, 0.267245888710022, -0.19161367416381836, 0.053290851414203644, -0.36559200286865234, 0.13718417286872864, 0.6847219467163086, -0.6552464365959167, -0.01993478834629059, 0.20937520265579224, -0.4695011377334595, 0.10200235247612, -0.0548650287091732, 0.03850864991545677, 0.16700479388237, -1.3750569820404053, -0.08511523902416229, -0.02725159376859665, -0.4032372832298279, -0.6758159399032593, -0.1930159330368042, -0.09288192540407181, 0.3543173372745514, 0.686080813407898, 0.39208200573921204, -0.011036578565835953, -0.05986612290143967, -0.2303474396467209, -0.3637860417366028, 0.17015764117240906, 0.0865301787853241, 0.06409253180027008, 0.03617081046104431, -0.20874415338039398, 0.18845264613628387, -0.4128386378288269, 0.44660210609436035, 0.6875894665718079, 1.1724520921707153, -0.018593020737171173, 0.06301946938037872, 0.24696901440620422, 0.12024759501218796, -0.3570813238620758, 0.06043991446495056, 0.6140186786651611, 0.15174147486686707, -0.09880655258893967, 0.06166447699069977, 0.040826160460710526, 0.16017279028892517, -0.03681819885969162, -0.3156448304653168, -0.3994772136211395, 0.24783042073249817, -0.04439377784729004, 0.5423014760017395, -0.3107835650444031, -0.12587463855743408, 0.061405643820762634, 0.1452949047088623, 0.18871745467185974, -0.14015698432922363, -0.5298288464546204, -0.2677522599697113, -0.19761651754379272, -0.20519256591796875, -0.5896915197372437, -0.001052267849445343, 0.0032635480165481567, 0.09842567145824432, -0.25293105840682983, -0.33894461393356323, -0.38015109300613403, -0.21489062905311584, 0.07187383621931076, 0.04394400119781494, -0.16563090682029724, -0.12748204171657562, 0.3433246612548828, -0.10164390504360199, -0.09651003777980804, -0.1858786940574646, -0.1543092131614685, -0.32837215065956116, 0.24863694608211517, -0.04438374564051628, 0.5795191526412964, -0.27430009841918945, 0.17831523716449738, -0.051502227783203125, -6.775228500366211, 0.3329446315765381, 0.44418489933013916, 0.6185945272445679, 0.03143812343478203, -0.08682160824537277, 0.02635733224451542, -0.2838878929615021, 0.4536976218223572, 0.26894640922546387, 0.05400434136390686, 0.13895508646965027, -0.5602370500564575, -0.28486377000808716, -2.2810306549072266, -0.23678956925868988, -0.04013300687074661, 0.14271698892116547, 0.4974026381969452, 0.17931626737117767, -0.007917419075965881, -0.22200681269168854, 0.061511360108852386, -0.2311234325170517, -0.3865489363670349, 0.05972546711564064, -0.26064902544021606, 0.26178932189941406, 0.007455865852534771, 0.1560983806848526, 0.069517120718956, -0.04812081530690193, 0.09527456760406494, 0.1234176978468895, -0.247956782579422, -0.03175777196884155, 0.00022167712450027466, 0.07274645566940308, -0.10917140543460846, -0.1554717868566513, -0.08024774491786957, 0.9606496095657349, -0.11635122448205948, 0.10187317430973053, 0.14942245185375214, -0.46480798721313477, -0.17891573905944824, 0.13374698162078857, -0.11139452457427979, 0.49896949529647827, 0.158063605427742, 0.2202167510986328, -0.4213140606880188, -0.4635975658893585, -0.5646133422851562, 0.11969872564077377, -0.06925352662801743, 0.33338233828544617, -0.4529873728752136, -0.11711887270212173, -0.37466683983802795, 0.03372940421104431, 0.22991029918193817, -0.7343228459358215, -0.38501039147377014, 0.18584558367729187, 0.5644587874412537, 0.22350716590881348, -0.3255733251571655, 0.11366349458694458, 0.2537009119987488, 0.18445324897766113, 0.4313206076622009, 0.23273338377475739, 0.31127452850341797, 0.003870743326842785, -0.20405927300453186, -0.3564799427986145, 0.017408594489097595, -0.25536012649536133, 0.464195191860199, 0.19067324697971344, -0.3823571503162384, 0.1324649155139923, 0.7610570192337036, 0.39746302366256714, -0.16123434901237488, -0.09756959974765778, -0.4584231376647949, -0.1607893854379654, 0.39231687784194946, 0.609991729259491, 0.056481361389160156, -0.02962157502770424, -0.5916069746017456, 0.3010619878768921, 0.3694615960121155, -0.12422307580709457, 0.18352238833904266, 0.157128244638443, -0.01680116355419159, -0.14354845881462097, -0.3220303952693939, -0.20728394389152527, 0.49397051334381104, 0.11728496104478836, -0.7547416687011719, 0.1578977108001709, 0.39308661222457886, -0.01119278371334076, -0.339430034160614, 0.3137660026550293, 0.5066874027252197, -0.4640701413154602, -0.23208975791931152, -0.17028026282787323, -0.5062720775604248, -0.054895877838134766, -0.17942124605178833, 0.3294796347618103, 0.21339571475982666, 0.3477175831794739, 0.3039551377296448, -0.16598330438137054, -0.07974407821893692, 0.44235941767692566, -0.15965037047863007, -0.12792252004146576, 0.14800278842449188, 0.06495148688554764, -0.4822830259799957, -0.28307831287384033, -0.11442957818508148, 0.19898934662342072, -0.15811465680599213, 0.3932209610939026, -0.1419757455587387, 0.09340927749872208, 0.43757885694503784, -0.3824598789215088, 0.31561872363090515, 0.1853369176387787, -0.11136917024850845, -0.08309067785739899, -0.09551394730806351, 0.26142507791519165, 0.28049856424331665, 0.43677228689193726, -0.3158184587955475, -0.05566404014825821, -0.09923627227544785, -0.026743208989501, -0.2638525068759918, -0.1700735092163086, 0.1323622316122055, 0.8783661127090454, -0.422215074300766, -0.02177564799785614, 0.026053359732031822, -0.5390021204948425, -0.002611946314573288, 0.1400126814842224, -0.09166818857192993, -0.020419754087924957, 0.27058014273643494, -0.22937142848968506, 1.1134790182113647, 0.14235806465148926, -0.23257745802402496, -0.20786355435848236, 0.36515742540359497, 0.315049946308136, -0.2997609078884125, 0.03707544505596161, -0.179259791970253, 0.25293755531311035, 0.18943536281585693, -0.11185348033905029, -0.7907484173774719, -0.43414562940597534, 0.1130589097738266, -0.3273024260997772, 0.013866811990737915, -0.34410586953163147, 0.10549764335155487, -0.15805234014987946, 0.08795373886823654, -0.07902077585458755, 0.16890963912010193, 0.16919520497322083, -0.057434819638729095, 0.22005942463874817, -0.22579219937324524, -0.22858518362045288, -0.01230684295296669, -0.30906060338020325, 0.19101569056510925, -0.4153735339641571, 0.020793329924345016, -0.4039265811443329, 0.3736504912376404, -0.30636563897132874, -0.3528556227684021, 0.140954852104187, -0.34472575783729553, 0.5919870138168335, 0.13112173974514008, 0.24621838331222534, 0.2814444601535797, -0.12788905203342438, 0.23103807866573334, 0.12583321332931519, 0.24146927893161774, -0.621396005153656, -0.4561384320259094, 0.05683061480522156, 0.36398571729660034, 0.07697302103042603, -0.4336978793144226, 0.33541399240493774, 0.9603136777877808, -0.4088152050971985, 0.4390433132648468, -0.22687479853630066, 0.017809711396694183, -0.32494139671325684, -0.4092247188091278, -0.3619712293148041, 0.5490106344223022, -1.1882007122039795, 0.08904393017292023, -0.06472812592983246, -0.43779730796813965, -0.19240443408489227, 0.08301223069429398, -0.6107684373855591, 0.12532691657543182, 0.2641572058200836, -0.3553626537322998, -0.3507516086101532, 0.30751803517341614, -0.4870065748691559, -0.6090989708900452, 0.2393181324005127, 0.16696752607822418, -0.25878119468688965, -0.1299724280834198, 0.4710826873779297, 0.09846210479736328, -0.2297966182231903, 0.32066795229911804, -0.3715991973876953, 0.05525730550289154, -0.33491307497024536, 0.17577393352985382, 0.28655630350112915, 0.354963093996048, 0.38358935713768005, 0.13443386554718018, -0.4705613851547241, -0.39198294281959534, -0.1235518679022789, -0.013309329748153687, -0.811621904373169, 0.28361013531684875, 0.10532708466053009, -0.2218615561723709, -0.08219070732593536, -1.0312546491622925, 0.436692476272583, 0.6740620732307434, 0.11039087176322937, -0.44290053844451904, 0.09625647962093353, 0.3230637013912201, -0.762469470500946, -0.07519690692424774, 0.16193971037864685, -0.10360713303089142, -0.07688583433628082, 0.4954788088798523, -0.23159068822860718, 0.46226775646209717, 0.2698574960231781, 0.4112229347229004, 0.16413259506225586, -1.0708637237548828, 0.09853675961494446, -0.031542643904685974, 0.04670249670743942, -0.4436977505683899, -0.623668909072876, -0.0697033703327179, 0.33173125982284546, -0.14810863137245178, 0.08294945955276489, -0.0033083483576774597, -1.4967525005340576, -0.8439145088195801, 0.1014384999871254, 0.08591610193252563, -0.08261485397815704, 0.04902864992618561, 0.08527448773384094, -0.014194309711456299, -0.022064208984375, 0.008251696825027466, 0.5507628917694092, 0.04581519961357117, 0.013831958174705505, -0.011101935058832169, -0.6167188882827759, 0.1694869101047516, 0.3914831280708313, 0.26912879943847656, 0.27225029468536377, 0.42886674404144287, -0.0691051110625267, 0.7165569067001343, 0.2770821452140808, -0.25505930185317993, 0.563875675201416, -0.3264828622341156, 0.0363239049911499, -0.27371639013290405, 0.010977774858474731, 0.08983846008777618, -0.02162175625562668, -0.139963299036026, -0.42279067635536194, 0.33434492349624634, -0.32767605781555176, -0.520395815372467, 0.10511363297700882, 0.3109859228134155, 0.050407350063323975, -0.42781999707221985, 0.11055705696344376, 0.2557794749736786, 0.5447006821632385, -0.9214514493942261, -0.04453360289335251, -0.3298516869544983, -0.6947367191314697, -0.5393738746643066, 0.21290338039398193, -0.04373009502887726, -0.021282479166984558, -0.1464141607284546, 0.2335769683122635, -0.5315607190132141, 0.6704803705215454, 0.2335224747657776, 0.2171708345413208, 0.17044992744922638, 0.2818460166454315, -0.25484776496887207, 0.5288475155830383, 0.01283852756023407, -0.228117436170578, 0.03905108571052551, -0.34427836537361145, -0.12936612963676453, 0.25420498847961426, -0.12152396142482758, 0.37763381004333496, -0.17199461162090302, -0.007082253694534302, -0.009179669432342052, 0.0016343332827091217, -0.20359650254249573, -0.14726606011390686, -0.09788523614406586, -0.29448699951171875, -0.03589354455471039, 0.20943230390548706, -0.2760860323905945, -0.14314991235733032, -0.14278331398963928, 0.22370806336402893, 0.2016836404800415, -0.03527446836233139, 0.2212069183588028, -0.13905222713947296, 0.13981834053993225, 0.4354678988456726, 0.06190036982297897, -0.5119094252586365, 0.1576833575963974, 0.4748838245868683, -0.027838610112667084, -0.3163527548313141, 0.09302422404289246, -0.09117338061332703, -0.21539166569709778, 0.22644804418087006, -0.03738084435462952, -0.04468110203742981, 0.25497570633888245, -0.8440040349960327, 0.353721559047699, -0.43217045068740845, 0.039665959775447845, 0.07354358583688736, -0.030057445168495178, -0.35604971647262573, 0.05344883352518082, 0.04564020410180092, -0.46753057837486267, -0.11513695865869522, -0.06979250907897949, 0.1324499547481537, 0.37979429960250854, 0.35877445340156555, 0.1628965437412262, 0.0727538913488388, 0.16985201835632324, 1.1635445356369019, 0.04351620376110077, -0.27003416419029236]\n"
     ]
    }
   ],
   "source": [
    "example_embedding = train_dataset_with_embeddings[0]['embeddings']\n",
    "print(f\"Example embedding shape: {example_embedding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7935/7935 [01:10<00:00, 113.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filepaths added:\n",
      "Dataset({\n",
      "    features: ['image', 'embeddings', 'filepath'],\n",
      "    num_rows: 7935\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Keep track of file paths (useful for FAISS index later)\n",
    "# Add the file paths as a new column\n",
    "def add_filepath(example):\n",
    "    # The 'image' field in datasets loaded with imagefolder contains the path\n",
    "    # Check if 'path' attribute exists, common in newer versions or specific configurations\n",
    "    if hasattr(example['image'], 'filename'):\n",
    "         example['filepath'] = example['image'].filename\n",
    "    # Fallback if filename attribute isn't directly available (might need adjustment based on dataset object structure)\n",
    "    # elif isinstance(example['image'], dict) and 'path' in example['image']:\n",
    "    #    example['filepath'] = example['image']['path']\n",
    "    else:\n",
    "         # If the structure is different, you might need to inspect example['image']\n",
    "         # For PIL images loaded directly, the path might not be automatically stored this way.\n",
    "         # load_dataset(\"imagefolder\") usually stores it.\n",
    "         print(f\"Warning: Could not determine file path for an image. Image data type: {type(example['image'])}\")\n",
    "         example['filepath'] = None # Or handle as appropriate\n",
    "    return example\n",
    "\n",
    "train_dataset_with_embeddings = train_dataset_with_embeddings.map(add_filepath)\n",
    "\n",
    "print(\"Filepaths added:\")\n",
    "print(train_dataset_with_embeddings)\n",
    "# Check an example:\n",
    "# print(f\"Example filepath: {train_dataset_with_embeddings[0]['filepath']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings and filepaths...\n",
      "Embeddings shape: (7935, 512)\n",
      "Creating FAISS index (IndexFlatL2) with dimension 512...\n",
      "Adding 7935 embeddings to the index...\n",
      "Index populated. Total vectors in index: 7935\n",
      "Saving FAISS index to faiss_clip_index.bin...\n",
      "Saving filepaths to filepaths.list...\n",
      "Index and filepaths saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Create and Populate FAISS Index\n",
    "import faiss\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Extract Embeddings and Filepaths ---\n",
    "print(\"Extracting embeddings and filepaths...\")\n",
    "# Ensure embeddings are in a NumPy array of type float32, which FAISS prefers\n",
    "embeddings = np.array(train_dataset_with_embeddings[\"embeddings\"], dtype=np.float32)\n",
    "filepaths = train_dataset_with_embeddings[\"filepath\"]\n",
    "\n",
    "# --- Check Dimensions ---\n",
    "if embeddings.ndim == 1:\n",
    "    # Handle case where map might have returned a list of lists instead of a 2D array\n",
    "    # This can sometimes happen depending on batching/error handling nuances\n",
    "    print(\"Warning: Embeddings array seems 1D, attempting to reshape or stack.\")\n",
    "    # Example check: are all elements arrays themselves?\n",
    "    if all(isinstance(e, np.ndarray) for e in embeddings):\n",
    "         embeddings = np.vstack(embeddings).astype(np.float32)\n",
    "    else:\n",
    "         raise ValueError(\"Embeddings are not in the expected 2D array format. Check the compute_embeddings function.\")\n",
    "\n",
    "if embeddings.shape[0] != len(filepaths):\n",
    "    raise ValueError(f\"Mismatch between number of embeddings ({embeddings.shape[0]}) and filepaths ({len(filepaths)}). Check data processing.\")\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\") # Should be (num_images, embedding_dim)\n",
    "embedding_dim = embeddings.shape[1]\n",
    "\n",
    "# --- Create FAISS Index ---\n",
    "# Using IndexFlatL2 for exact search with L2 distance (Euclidean distance)\n",
    "# Other index types exist for approximate nearest neighbors (faster, less exact)\n",
    "print(f\"Creating FAISS index (IndexFlatL2) with dimension {embedding_dim}...\")\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "# --- Add Embeddings to Index ---\n",
    "print(f\"Adding {embeddings.shape[0]} embeddings to the index...\")\n",
    "index.add(embeddings)\n",
    "print(f\"Index populated. Total vectors in index: {index.ntotal}\")\n",
    "\n",
    "# --- Save Index and Filepaths ---\n",
    "index_filename = \"faiss_clip_index.bin\"\n",
    "filepaths_filename = \"filepaths.list\" # Simple text file for filepaths\n",
    "\n",
    "print(f\"Saving FAISS index to {index_filename}...\")\n",
    "faiss.write_index(index, index_filename)\n",
    "\n",
    "print(f\"Saving filepaths to {filepaths_filename}...\")\n",
    "with open(filepaths_filename, 'w') as f:\n",
    "    for path in filepaths:\n",
    "        f.write(f\"{path}\\n\")\n",
    "\n",
    "print(\"Index and filepaths saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Test Similarity Search\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random # To pick a random query image\n",
    "import os\n",
    "\n",
    "# --- Load Index and Filepaths ---\n",
    "index_filename = \"faiss_clip_index.bin\"\n",
    "filepaths_filename = \"filepaths.list\"\n",
    "\n",
    "print(f\"Loading FAISS index from {index_filename}...\")\n",
    "index = faiss.read_index(index_filename)\n",
    "print(f\"Index loaded. Total vectors: {index.ntotal}\")\n",
    "\n",
    "print(f\"Loading filepaths from {filepaths_filename}...\")\n",
    "with open(filepaths_filename, 'r') as f:\n",
    "    loaded_filepaths = [line.strip() for line in f.readlines()]\n",
    "print(f\"Loaded {len(loaded_filepaths)} filepaths.\")\n",
    "\n",
    "# --- Search Function ---\n",
    "def find_similar_images(image_path, top_k=5):\n",
    "    \"\"\"\n",
    "    Takes an image path, computes its embedding, searches the FAISS index,\n",
    "    and returns the filepaths of the top_k most similar images.\n",
    "    \"\"\"\n",
    "    print(f\"\\nSearching for images similar to: {image_path}\")\n",
    "    try:\n",
    "        # Load and process the query image\n",
    "        query_image = Image.open(image_path).convert(\"RGB\")\n",
    "        inputs = processor(text=None, images=query_image, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "        # Move inputs to the correct device\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Get embedding\n",
    "        with torch.no_grad():\n",
    "            query_embedding = model.get_image_features(**inputs)\n",
    "\n",
    "        # Move to CPU and ensure float32\n",
    "        query_embedding = query_embedding.cpu().numpy().astype(np.float32)\n",
    "\n",
    "        # FAISS Search\n",
    "        # index.search returns distances (D) and indices (I) of neighbors\n",
    "        distances, indices = index.search(query_embedding, top_k)\n",
    "\n",
    "        # Retrieve filepaths using indices\n",
    "        results = []\n",
    "        print(\"Found similar images:\")\n",
    "        for i in range(top_k):\n",
    "            neighbor_index = indices[0][i]\n",
    "            distance = distances[0][i]\n",
    "            filepath = loaded_filepaths[neighbor_index]\n",
    "            results.append({\"filepath\": filepath, \"distance\": distance})\n",
    "            print(f\"  - Index: {neighbor_index}, Distance: {distance:.4f}, Path: {filepath}\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Query image not found at {image_path}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during search: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- Example Usage ---\n",
    "# Pick a random image from the loaded filepaths list to use as a query\n",
    "if loaded_filepaths:\n",
    "    query_image_index = random.randint(0, len(loaded_filepaths) - 1)\n",
    "    query_image_path = loaded_filepaths[query_image_index]\n",
    "\n",
    "    # Make sure the path exists (sometimes paths in datasets can be relative/absolute issues)\n",
    "    if os.path.exists(query_image_path):\n",
    "         # Perform the search\n",
    "         similar_images = find_similar_images(query_image_path, top_k=5)\n",
    "\n",
    "         # Optional: Display the query image and top result (requires matplotlib)\n",
    "         try:\n",
    "             import matplotlib.pyplot as plt\n",
    "\n",
    "            #  if similar_images:\n",
    "            #      # Display Query Image\n",
    "            #      plt.figure(figsize=(10, 5))\n",
    "            #      plt.subplot(1, 2, 1)\n",
    "            #      plt.imshow(Image.open(query_image_path))\n",
    "            #      plt.title(f\"Query Image:\\n{os.path.basename(query_image_path)}\")\n",
    "            #      plt.axis('off')\n",
    "\n",
    "            #      # Display Top Result\n",
    "            #      top_result_path = similar_images[0]['filepath']\n",
    "            #      if os.path.exists(top_result_path):\n",
    "            #           plt.subplot(1, 2, 2)\n",
    "            #           plt.imshow(Image.open(top_result_path))\n",
    "            #           plt.title(f\"Top Result (Dist: {similar_images[0]['distance']:.4f}):\\n{os.path.basename(top_result_path)}\")\n",
    "            #           plt.axis('off')\n",
    "            #      else:\n",
    "            #           print(f\"Warning: Top result image path not found: {top_result_path}\")\n",
    "\n",
    "\n",
    "            #      plt.tight_layout()\n",
    "            #      plt.show()\n",
    "                 \n",
    "            #  else:\n",
    "            #      print(\"No similar images found to display.\")\n",
    "\n",
    "         except ImportError:\n",
    "             print(\"\\nInstall matplotlib (pip install matplotlib) to display images.\")\n",
    "         except Exception as e:\n",
    "             print(f\"Could not display images due to error: {e}\")\n",
    "    else:\n",
    "        print(f\"Error: The randomly selected query image path does not exist: {query_image_path}\")\n",
    "        print(\"Please ensure the paths in filepaths.list are correct and accessible.\")\n",
    "\n",
    "else:\n",
    "    print(\"No filepaths loaded, cannot run example search.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
